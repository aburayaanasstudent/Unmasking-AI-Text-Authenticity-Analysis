# Unmasking-AI-Text-Authenticity-Analysis - Detecting LLM-Generated Essays Using Advanced NLP Techniques

# Overview
Welcome to Unmasking AI, a graduation project focused on detecting essays generated by Large Language Models (LLMs). Using advanced NLP techniques, this project aims to differentiate between human-written and machine-generated text with high accuracy.

In this repository, you’ll find:

Source code for feature extraction
Model training scripts
Evaluation metrics and results
Documentation detailing the methodology and hypotheses
Project Motivation
As LLMs become more sophisticated, it is increasingly difficult to distinguish human-authored text from AI-generated text. This project was designed to address the growing challenge of text authenticity verification. By identifying distinguishing features in the text—such as stylistic indicators, linguistic patterns, and semantic embeddings—our model helps ensure transparency and integrity in textual content.

# Features & Approach
# 1 Data Collection

Three extensive text-only datasets were used.
Both human-written and LLM-generated samples were included.
# 2 Manual Feature Extraction

BERT Embeddings: Capture contextual information.
Sentiment Scores: Identify emotional tone and intensity.
Text Readability: Gauge the complexity and structure of the text.
POS Tagging: Analyze grammatical structure and usage patterns.
Repetitiveness: Measure repeated phrases and constructs.
# 3 Statistical Hypotheses

Each feature selection was backed by statistical tests and exploratory data analysis.
Ensures that chosen features significantly contribute to model performance.
# 4 Model Development

Features were fed into a classification model (e.g., an ensemble or a deep learning classifier) for training.
Hyperparameter tuning and cross-validation were used to optimize performance.
# 5 Performance

Achieved high precision and recall in distinguishing AI-generated essays.
Demonstrated outstanding robustness across diverse text domains.
